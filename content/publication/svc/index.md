---
abstract: "The study of strategic or adversarial manipulation of testing data to
  fool a classifier has attracted much recent attention. Most previous works
  have focused on two extreme situations where any testing data point either is
  completely adversarial or always equally prefers the positive label. In this
  paper, we generalize both of these through a unified framework for strategic
  classification and introduce the notion of strategic VC-dimension (SVC) to
  capture the PAC-learnability in our general strategic setup. SVC provably
  generalizes the recent concept of adversarial VC-dimension (AVC) introduced by
  Cullina et al. (2018). We instantiate our framework for the fundamental
  strategic linear classification problem. We fully characterize: (1) the
  statistical learnability of linear classifiers by pinning down its SVC; (2)
  it's computational tractability by pinning down the complexity of the
  empirical risk minimization problem. Interestingly, the SVC of linear
  classifiers is always upper bounded by its standard VC-dimension. This
  characterization also strictly generalizes the AVC bound for linear
  classifiers (Cullina et al., 2018)."
slides: svc
url_pdf: https://arxiv.org/abs/2012.03310
publication_types:
  - "2"
  - "1"
authors:
  - Ravi Sundaram
  - Anil Vullikanti
  - Haifeng Xu
  - admin
author_notes:
  - Equal contribution
  - Equal contribution
  - Equal contribution
  - Equal contribution
publication: "*The Journal of Machine Learning Research* (<font color=red>JMLR</font>), Shorter
  version at *ICML, 2021* (<font color=red>oral presentation, 3%</font>)"
summary: >-
  We establish a unified framework for strategic classification problems and
  introduce the notion of strategic VC-dimension (SVC) to capture its
  PAC-learnability. We instantiate our framework for the fundamental strategic linear classification problem and fully characterize: (1) the statistical learnability of linear classifiers by pinning down its SVC; (2) it's computational tractability by pinning down the complexity of the empirical risk minimization problem. 
url_dataset: ""
url_project: ""
publication_short: "<br />*The Journal of Machine Learning Research (JMLR)*, shorter version at *ICML, 2021* (<font color=red>oral presentation, 3%</font>) "
url_source: https://arxiv.org/abs/2012.03310
url_video: https://icml.cc/virtual/2021/poster/9137
title: PAC-Learning for Strategic Classification
doi: ""
featured: true
tags: []
projects:
  - svc
image:
  caption: "Image credit: [**Unsplash**](https://unsplash.com/photos/pLCdAaMFLTE)"
  focal_point: center
  preview_only: true
  filename: icml21-svc-poster_00_00.jpg
date: 2021-12-04T21:56:14.075Z
url_slides: https://icml.cc/virtual/2021/poster/9137
publishDate: 2017-01-01T00:00:00.000Z
url_poster: https://icml.cc/virtual/2021/poster/9137
url_code: ""
---
